{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiQCvdxI/5Id6wD9QrQ8hT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariemouertani104/Building-AI-Agent/blob/main/Biulding_ai_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "pLvreFAt6iBb",
        "outputId": "ec41e415-cd98-4626-b6a9-741175988cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished\n",
            "Evaluation results over 10 episodes\n",
            "Average number of steps : 10.0\n",
            "Average total reward    : 11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# -------------------------\n",
        "# Environment with obstacles\n",
        "# -------------------------\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, size=6, obstacles=None):\n",
        "        self.size = size\n",
        "\n",
        "        if obstacles is None:\n",
        "            self.obstacles = [(1,2),(2,2),(3,2),(4,1),(4,2)]\n",
        "        else:\n",
        "            self.obstacles = obstacles\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_pos = [0, 0]\n",
        "        return self.get_state()\n",
        "\n",
        "    def get_state(self):\n",
        "        return self.agent_pos[0] * self.size + self.agent_pos[1]\n",
        "\n",
        "    def is_obstacle(self, pos):\n",
        "        return tuple(pos) in self.obstacles\n",
        "\n",
        "    def step(self, action):\n",
        "        # 0=up, 1=down, 2=left, 3=right\n",
        "\n",
        "        old_pos = self.agent_pos.copy()\n",
        "\n",
        "        if action == 0:\n",
        "            new_pos = [self.agent_pos[0]-1, self.agent_pos[1]]\n",
        "        elif action == 1:\n",
        "            new_pos = [self.agent_pos[0]+1, self.agent_pos[1]]\n",
        "        elif action == 2:\n",
        "            new_pos = [self.agent_pos[0], self.agent_pos[1]-1]\n",
        "        else:\n",
        "            new_pos = [self.agent_pos[0], self.agent_pos[1]+1]\n",
        "\n",
        "        # Check boundaries\n",
        "        if (0 <= new_pos[0] < self.size) and (0 <= new_pos[1] < self.size):\n",
        "            # Check obstacle\n",
        "            if not self.is_obstacle(new_pos):\n",
        "                self.agent_pos = new_pos\n",
        "\n",
        "        done = (self.agent_pos == [self.size-1, self.size-1])\n",
        "\n",
        "        if done:\n",
        "            reward = 20\n",
        "        else:\n",
        "            reward = -1\n",
        "\n",
        "        return self.get_state(), reward, done\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Q-learning Agent\n",
        "# -------------------------\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, n_states, n_actions):\n",
        "        self.q_table = np.zeros((n_states, n_actions))\n",
        "\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon = 0.2\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.randint(0, 3)\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state])\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        best_next = np.max(self.q_table[next_state])\n",
        "\n",
        "        self.q_table[state, action] += self.alpha * (\n",
        "            reward + self.gamma * best_next - self.q_table[state, action]\n",
        "        )\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Visualization\n",
        "# -------------------------\n",
        "\n",
        "def draw_grid(env, path=None):\n",
        "    grid = np.zeros((env.size, env.size))\n",
        "\n",
        "    for (r, c) in env.obstacles:\n",
        "        grid[r, c] = -1\n",
        "\n",
        "    goal = (env.size-1, env.size-1)\n",
        "    grid[goal] = 2\n",
        "\n",
        "    if path is not None:\n",
        "        for (r, c) in path:\n",
        "            grid[r, c] = 0.5\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(grid)\n",
        "    plt.xticks(range(env.size))\n",
        "    plt.yticks(range(env.size))\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Training\n",
        "# -------------------------\n",
        "\n",
        "env = GridWorld(size=6)\n",
        "\n",
        "n_states = env.size * env.size\n",
        "n_actions = 4\n",
        "\n",
        "agent = QLearningAgent(n_states, n_actions)\n",
        "\n",
        "episodes = 800\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done = env.step(action)\n",
        "        agent.learn(state, action, reward, next_state)\n",
        "        state = next_state\n",
        "\n",
        "print(\"Training finished\")\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Test + path extraction\n",
        "# -------------------------\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "\n",
        "def run_episode(env, agent, max_steps=100):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    steps = 0\n",
        "    total_reward = 0\n",
        "\n",
        "    path = []\n",
        "\n",
        "    while not done and steps < max_steps:\n",
        "        row = state // env.size\n",
        "        col = state % env.size\n",
        "        path.append((row, col))\n",
        "\n",
        "        action = np.argmax(agent.q_table[state])\n",
        "        next_state, reward, done = env.step(action)\n",
        "\n",
        "        total_reward += reward\n",
        "        state = next_state\n",
        "        steps += 1\n",
        "\n",
        "    path.append((env.size-1, env.size-1))\n",
        "\n",
        "    return steps, total_reward, path\n",
        "\n",
        "\n",
        "# run several evaluation episodes\n",
        "n_tests = 10\n",
        "\n",
        "steps_list = []\n",
        "rewards_list = []\n",
        "\n",
        "for _ in range(n_tests):\n",
        "    steps, total_reward, path = run_episode(env, agent)\n",
        "    steps_list.append(steps)\n",
        "    rewards_list.append(total_reward)\n",
        "\n",
        "print(\"Evaluation results over\", n_tests, \"episodes\")\n",
        "print(\"Average number of steps :\", np.mean(steps_list))\n",
        "print(\"Average total reward    :\", np.mean(rewards_list))\n",
        "\n",
        "\n",
        "# visualize one episode\n",
        "draw_grid(env, path)\n",
        "\n",
        "\n"
      ]
    }
  ]
}